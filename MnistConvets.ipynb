{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wr2om2eJtdhT"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) =mnist.load_data()\n",
        "# the MNIST dataset is loaded and split into training and testing sets. train_images and train_labels represent the training data and their corresponding labels, while test_images and test_labels represent the testing data and their respective labels from the MNIST dataset."
      ],
      "metadata": {
        "id": "rzzlGj-Btt44"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "YcysU3UiuORs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =models.Sequential()\n",
        "#a sequential model is instantiated using the Keras deep learning framework.\n",
        "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(28,28,1)))\n",
        "#a 2D convolutional layer with 32 filters of size (3,3), using the ReLU activation function, is added to the model with an input shape of (28, 28, 1).\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        " #2D max pooling layer with a pool size of (2,2) is added to the model, reducing the spatial dimensions of the input data by a factor of 2 in both height and width.\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "#a 2D convolutional layer with 64 filters of size (3,3), using the ReLU activation function\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "#2D max pooling layer with a pool size of (2,2) is added to the model, reducing the spatial dimensions of the input data by a factor of 2 in both height and width\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "#a 2D convolutional layer with 64 filters of size (3,3), using the ReLU activation function"
      ],
      "metadata": {
        "id": "b_DOWR-iuaq3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#model.summary() provides a detailed summary of the architecture and parameters of the deep learning model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtQbzwFrud17",
        "outputId": "b51a7090-3bb9-4d53-ace1-36cae0bf4c63"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "#a flatten layer is added to the model, transforming the multi-dimensional output of the previous layer into a one-dimensional vector.\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "#a dense layer with 64 units and ReLU activation function is added to the model.\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "#a dense layer with 10 units and softmax activation function is added to the model, representing the output layer for multi-class classification tasks."
      ],
      "metadata": {
        "id": "1wyWa9Ibuocw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#model.summary() provides a detailed summary of the architecture and parameters of the deep learning model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny8axWa1uwjd",
        "outputId": "1cd55bca-6960-4a99-fced-ab21ee84d5bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "# the to_categorical function is imported from the keras.utils module, which is used for one-hot encoding the categorical target labels in multi-class classification tasks."
      ],
      "metadata": {
        "id": "5jBSp_8luzSH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "## the MNIST dataset is loaded and split into training and testing sets. train_images and train_labels represent the training data and their corresponding labels, while test_images and test_labels represent the testing data and their respective labels from the MNIST dataset."
      ],
      "metadata": {
        "id": "1Tfh1t21QitF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000,28,28,1))\n",
        "#the train_images array is reshaped to have dimensions (60000, 28, 28, 1) to match the required input shape for a Convolutional Neural Network (CNN) with one channel (grayscale images).\n",
        "train_images = train_images.astype('float32')/255\n",
        "#train_images array is converted to float32 data type and then normalized by dividing each pixel value by 255 to scale the image data between 0 and 1, making it suitable for deep learning model training.\n",
        "test_images = test_images.reshape(10000,28,28,1)\n",
        "#test_images array is converted to float32 data type and then normalized by dividing each pixel value by 255 to scale the image data between 0 and 1, making it suitable for deep learning model training.\n",
        "test_images = test_images.astype('float32')/255\n",
        "#test_images array is converted to float32 data type and then normalized by dividing each pixel value by 255 to scale the image data between 0 and 1, making it suitable for deep learning model training."
      ],
      "metadata": {
        "id": "jOFi6ap3Q_-X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "#the train_labels array is one-hot encoded using the to_categorical function to convert the categorical labels into a binary matrix representation for multi-class classification tasks.\n",
        "test_labels = to_categorical(test_labels)\n",
        "#the test_labels array is one-hot encoded using the to_categorical function to convert the categorical labels into a binary matrix representation for multi-class classification tasks"
      ],
      "metadata": {
        "id": "InMwWK9bR43I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= 'rmsprop', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#the model is compiled with the RMSprop optimizer, categorical cross-entropy loss function, and accuracy metric for training a multi-class classification task."
      ],
      "metadata": {
        "id": "laJTmmpdSVCp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs= 5, batch_size= 64)\n",
        "#the model is trained on the train_images and train_labels data for 5 epochs using a batch size of 64 samples per iteration."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US-9TjXqS_Au",
        "outputId": "5c25ae55-5179-4923-afef-f46656836ad5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 34s 35ms/step - loss: 0.1753 - accuracy: 0.9440\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0482 - accuracy: 0.9848\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.0324 - accuracy: 0.9902\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.0253 - accuracy: 0.9924\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0189 - accuracy: 0.9946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7892b6328580>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "#the trained model is evaluated on the test_images and test_labels, and the resulting test loss and test accuracy are stored in the variables test_loss and test_acc, respectively."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYZrmBKVTU3l",
        "outputId": "2869a024-53ff-4f03-dcc2-59558c9d600c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc\n",
        "#The variable test_acc represents the test accuracy, which indicates the model's performance on the test dataset."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y05eK8PEUhTB",
        "outputId": "c1d46497-6787-4df1-c899-c0647a623b3b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9890999794006348"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}